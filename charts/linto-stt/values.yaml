# Default values for linto-stt
# This is a YAML-formatted file.

global:
  domain: localhost
  imageTag: latest-unstable
  tls:
    enabled: true
    mode: mkcert
    acmeEmail: ""
    secretName: linto-tls  # Shared TLS secret across all charts
    createCertificate: false  # linto-studio creates the certificate
  storage:
    database:
      hostPath: ""  # Local storage for MongoDB, Redis
      nodeSelector: {}  # e.g., kubernetes.io/hostname: linto-gpu-01
    files:
      hostPath: ""  # NFS storage for models
  storageClass: ""

# API Gateway for STT services
apiGateway:
  enabled: true
  replicas: 1
  image:
    repository: lintoai/linto-api-gateway
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: "1"
      memory: 512Mi
    requests:
      cpu: 10m
      memory: 64Mi
  env:
    COMPONENTS: ApiWatcher,WebServer  # No ServiceWatcher on Kubernetes (no docker.sock)
  service:
    port: 80
  ingress:
    path: /gateway
    stripPrefix: false  # API Gateway routes already include /gateway prefix

# Whisper API service
whisper:
  enabled: true
  replicas: 1
  image:
    repository: lintoai/linto-transcription-service
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: "2"
      memory: 4Gi
    requests:
      cpu: 10m
      memory: 64Mi
  env:
    SERVICE_NAME: stt-all-whisper-v3-turbo
    LANGUAGE: "*"
    CONCURRENCY: "2"
    BROKER_PASS: ""
    SECURITY_LEVEL: "0"
  service:
    port: 80
  ingress:
    path: /stt-all-whisper-v3-turbo
    stripPrefix: true

# GPU Workers (whisper-worker + diarization in same pod)
# When both whisperWorkers and diarization are enabled, they run in the same pod
# sharing a single GPU. This avoids GPU allocation conflicts without time-slicing.
#
# replicasPerGpu: list where index = GPU index, value = replicas on that GPU
# Example: [1, 1] = 1 gpu-worker pod on GPU 0, 1 on GPU 1
# Example: [2, 2, 1, 1] = 2 pods on GPU 0 & 1, 1 pod on GPU 2 & 3
whisperWorkers:
  enabled: true
  replicasPerGpu: [1]  # Default: 1 worker on GPU 0 (single GPU setup)
  image:
    repository: lintoai/linto-stt-whisper
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
  env:
    SERVICE_NAME: stt-all-whisper-v3-turbo
    MODEL: large-v3-turbo
    LANGUAGE: "*"
    DEVICE: cuda
    CONCURRENCY: "1"
    BROKER_PASS: ""
    SECURITY_LEVEL: "0"

# Diarization service
# When enabled with whisperWorkers, runs in the same pod sharing the GPU.
# replicasPerGpu is ignored when combined with whisperWorkers (uses whisperWorkers.replicasPerGpu)
diarization:
  enabled: true
  replicasPerGpu: [1]  # Default: 1 diarization on GPU 0 (single GPU setup)
  image:
    repository: lintoai/linto-diarization-pyannote
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
  env:
    SERVICE_NAME: stt-diarization-pyannote
    QUEUE_NAME: diarization-pyannote
    DEVICE: cuda
    CONCURRENCY: "1"
    BROKER_PASS: ""
    MODEL_INFO: '{"en": "Yes", "fr": "Oui"}'

# Redis task broker (redis-stack-server required for JSON module used by diarization)
redis:
  enabled: true
  image:
    repository: redis/redis-stack-server
    tag: latest
    pullPolicy: IfNotPresent
  password: ""
  resources:
    limits: {}  # No limits for databases - they manage their own memory
    requests:
      cpu: 10m
      memory: 64Mi
  persistence:
    enabled: true
    size: 5Gi
    storageClass: ""
  service:
    port: 6379

# MongoDB for job metadata
mongodb:
  enabled: true
  image:
    repository: mongo
    tag: "6.0.2"
    pullPolicy: IfNotPresent
  resources:
    limits: {}  # No limits for databases - they manage their own memory
    requests:
      cpu: 10m
      memory: 64Mi
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""
  service:
    port: 27017
